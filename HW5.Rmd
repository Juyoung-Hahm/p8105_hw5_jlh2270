---
title: "P8105_HW5_jlh2270"
author: "Juyoung Hahm"
date: "11/17/2020"
output: html_document
---
```{r setup, include = FALSE}
library(tidyverse)
set.seed(1)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

Read in the data.
Create a city_state variable (e.g. “Baltimore, MD”) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).
```{r}
homicide_df = 
  read_csv("homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```


Let's look at this a bit

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.
```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate ........

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```


Create a plot that shows the estimates and CIs for each city
```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```



```{r, error = TRUE}
homicide_df = 
  read_csv("homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```

# Problem 2
```{r}
path = list.files(pattern = "*.csv") %>%
      map_df(~read_csv(.)) 
path$arm = c("control","control","control","control","control","control","control","control","control","control","experimental","experimental","experimental","experimental","experimental","experimental","experimental","experimental","experimental","experimental")
path$ID = c(1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10)

path
```


# Problem 3
Conduct a simulation to explore power in a one-sample t-test.
```{r}
ttest_sim = function(n, mu = 0, sigma = 5) {
  data_sim = tibble(
    x = rnorm(n = 30, mean = mu, sd = sigma),
  )
    ttest=t.test(data_sim, mu=0, sd=5)
    ttest[['p.value']]
    ttest[['estimate']]
   
  results_sim = tibble(
     pvalue = ttest[['p.value']],
     mean = ttest[['estimate']]
  )

}
```
Generate 5000 datasets from the model
```{r}
output = vector("list", 5000)

for (i in 1:5000) {
  output[[i]] = ttest_sim(30)
}

sim_results = bind_rows(output)
sim_results
```

Repeat for mu={1,2,3,4,5,6,7}
```{r}
mu_list =
  list(
    "mu_1" = 1,
    "mu_2" = 2,
    "mu_3" = 3,
    "mu_4" = 4,
    "mu_5" = 5,
    "mu_6" = 6,
    "mu_7" = 7
  )

output = vector("list", length = 7)

for (i in 1:7) {
  output[[i]] = rerun(5000, ttest_sim(mu_list[[i]])) %>% 
    bind_rows

}


graph_data =
bind_rows(output) %>%
mutate(
test_results = case_when(
pvalue < .05 ~ "reject",
pvalue >= .05 ~ "fail to reject"
))
a = slice(graph_data, 1:5000)
a$mu = rep(1,nrow(a))

b = slice(graph_data, 5001:10000)
b$mu = rep(2,nrow(b))

c = slice(graph_data, 10001:15000)
c$mu = rep(3,nrow(c))

d = slice(graph_data, 15001:20000)
d$mu = rep(4,nrow(d))

e = slice(graph_data, 20001:25000)
e$mu = rep(5,nrow(e))

f = slice(graph_data, 25001:30000)
f$mu = rep(6,nrow(f))

g = slice(graph_data, 30001:35000)
g$mu = rep(7,nrow(g))

graph_data = do.call("rbind", list(a,b,c,d,e,f,g))

```
Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.
```{r}
graph_data %>% 
  group_by(mu) %>%
  mutate(
    reject = ifelse(pvalue < '0.05', 1, 0)
       ) %>% 
  summarize(prop_reject = mean(reject)) %>% 
  ggplot(aes(x = mu, y = prop_reject)) +
  geom_point() +
  labs(
    title = "Proportion of times the null is rejected",
    x = "True Value of Mu",
    y = "Power")
```
Make a plot showing the average estimate of μ̂ on the y axis and the true value of μ on the x axis. 
```{r}
mu_hat = list( mean(a$mean), mean(b$mean), mean(c$mean), mean(d$mean), mean(e$mean), mean(f$mean),mean(g$mean))
true_mu = list(1,2,3,4,5,6,7)
```

```{r first plot}
plot(x = true_mu, y = mu_hat)
```

Make a second plot (or overlay on the first) the average estimate of μ̂ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis.
```{r}
a_reject = 
  a %>%
  filter(
    test_results == "reject"
  ) 
a_reject_average = mean(a_reject$mean)

b_reject = 
  b %>%
  filter(
    test_results == "reject"
  ) 
b_reject_average = mean(b_reject$mean)

c_reject = 
  c %>%
  filter(
    test_results == "reject"
  ) 
c_reject_average = mean(c_reject$mean)

d_reject = 
  d %>%
  filter(
    test_results == "reject"
  ) 
d_reject_average = mean(d_reject$mean)

e_reject = 
  e %>%
  filter(
    test_results == "reject"
  ) 
e_reject_average = mean(e_reject$mean)

f_reject = 
  f %>%
  filter(
    test_results == "reject"
  ) 
f_reject_average = mean(f_reject$mean)

g_reject = 
  g %>%
  filter(
    test_results == "reject"
  ) 
g_reject_average = mean(g_reject$mean)

mu_hat_reject = list(a_reject_average, b_reject_average, c_reject_average, d_reject_average, e_reject_average, f_reject_average, g_reject_average)
```
Is the sample average of μ̂ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?
```{r second plot}
plot(x = true_mu, y = mu_hat_reject)
```
It definitely got closer to the true mean when we only calculated rejected. Because if we rejected null, then it means that the mean could be bigger or less than the true mean.
